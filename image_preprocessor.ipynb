{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97d8be83a292de5a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from skimage.filters import sobel\n",
    "import shutil\n",
    "import random\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "import itertools"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T18:20:24.932997Z",
     "start_time": "2024-03-11T18:20:24.924021Z"
    }
   },
   "id": "5443fa741fcdb30d",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Paths\n",
    "After downloading the files from the link: \n",
    "change the path accordingly, and leave \\painting-to-artist\\dataset or \\painting-to-artist\\workspace as is."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e02786d19d29e6e4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset_path = os.path.abspath(r'D:\\Program Files (x86)\\painting-to-artist\\dataset')\n",
    "training_path = os.path.abspath(r'D:\\Program Files (x86)\\painting-to-artist\\workspace\\train')\n",
    "testing_path = os.path.abspath(os.path.join(r'D:\\Program Files (x86)\\painting-to-artist\\workspace\\test'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T18:20:24.996861Z",
     "start_time": "2024-03-11T18:20:24.978922Z"
    }
   },
   "id": "45026e8cb9f07cb0",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sampling the Images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d4b28c086eeba25"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def sample_images(data_path, train_path, test_path, n, ratio=0.8):\n",
    "    \"\"\"\n",
    "    This method samples the images from the dataset path to the training path and testing path.\n",
    "    :param data_path: The path to the data.\n",
    "    :param train_path: The path to which the training images will be copied.\n",
    "    :param test_path: The path to which the testing images will be copied.\n",
    "    :param n: The number of images aimed to be sampled.\n",
    "    :param ratio: The wanted ratio from the sampled data to be used for training. The rest will be used for testing.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    if ratio >= 1 or ratio <= 0:\n",
    "        raise ValueError(\"The ratio should be between 0 and 1 (non-inclusive)\")\n",
    "    \n",
    "    if ratio < 0.5:\n",
    "        warnings.warn(\"The ratio is less than 0.5, not advised for good training\")\n",
    "    \n",
    "    artists = os.listdir(data_path) # list of artists\n",
    "    \n",
    "    for artist in artists:\n",
    "        artist_path = os.path.join(data_path, artist)  # path to the artist\n",
    "        images = os.listdir(artist_path)               # list of images\n",
    "        random.shuffle(images)                         # shuffle the images inside the images list\n",
    "\n",
    "        ## Adjust the number of images based on availability\n",
    "        n_train = min(int(n * ratio), int(len(images) * ratio))  # 80% of the images\n",
    "        n_test = min(n-n_train, len(images) - n_train)           # 20% of the images\n",
    "\n",
    "        ## Partition the images to training and testing\n",
    "        train_images = images[:n_train]\n",
    "        test_images = images[n_train:n_train + n_test]\n",
    "\n",
    "        ## Create the directories for training and testing\n",
    "        artist_train_path = os.path.join(train_path, artist)\n",
    "        artist_test_path = os.path.join(test_path, artist)\n",
    "        os.makedirs(artist_train_path, exist_ok=True)\n",
    "        os.makedirs(artist_test_path, exist_ok=True)\n",
    "\n",
    "        # Create the directories\n",
    "        for image in train_images:\n",
    "            image_path = os.path.join(artist_path, image)\n",
    "            shutil.copy(image_path, os.path.join(artist_train_path, image))\n",
    "\n",
    "        for image in test_images:\n",
    "            image_path = os.path.join(artist_path, image)\n",
    "            shutil.copy(image_path, os.path.join(artist_test_path, image))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T18:20:25.012790Z",
     "start_time": "2024-03-11T18:20:24.999826Z"
    }
   },
   "id": "56259192f7a96cd2",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ??????????????????????? #\n",
    "sample_images(dataset_path, training_path, testing_path, 50, 0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T18:23:57.935583Z",
     "start_time": "2024-03-11T18:23:43.082822Z"
    }
   },
   "id": "48c0bbfd3ad707a0",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def clear_files(directory):\n",
    "    \"\"\"\n",
    "    Clears all files within the subdirectories of the given directory.\n",
    "    :param directory: The directory to clear its subcategories' files.\n",
    "    \"\"\"\n",
    "    \n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            os.remove(file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T18:20:42.519068Z",
     "start_time": "2024-03-11T18:20:42.506078Z"
    }
   },
   "id": "d11b748bda36074a",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "clear_files(training_path)\n",
    "clear_files(testing_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:03:54.137298Z",
     "start_time": "2024-03-11T19:03:53.536907Z"
    }
   },
   "id": "744d2571e0b33596",
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Preprocessing\n",
    "This section includes methods used to preprocess the data before feeding it to the model of our choice.\n",
    "The result will be a list of vectorized images and their corresponding labels."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd959855880e47e4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def resize_and_split(train_path, test_path, size=128):\n",
    "    \"\"\"\n",
    "    Resizes the images to the given size and splits the data into training and testing datasets.\n",
    "    :param train_path: The path from which the training images will be taken.\n",
    "    :param test_path: The path from which the testing images will be taken.\n",
    "    :param size: The row/column size to which the images will be resized.\n",
    "    :return: Lists of the training and testing images and their corresponding labels.\n",
    "    \"\"\"\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    \n",
    "    # The following loop reads the images from the training path, resizes them, and adds them to the list of images.\n",
    "    # It also adds the corresponding label for each image to the list of labels.\n",
    "    for directory_path in glob.glob(train_path+r'/*'):\n",
    "        label = directory_path.split(\"\\\\\")[-1] # extracts the artist name from the directory path.\n",
    "        # print(label)\n",
    "        for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_COLOR) # Read the image in color (BGR format)\n",
    "            img = cv2.resize(img, (size, size))          # Resize the image to the given size, using weighted average values for interpolation.\n",
    "            train_images.append(img)   # Add the processed image to the list of images\n",
    "            train_labels.append(label) # Add the label to the list of labels, matching the image in the same index in the images list.\n",
    "    \n",
    "    # Convert the lists to numpy arrays\n",
    "    train_images = np.array(train_images)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    ##################\n",
    "    \n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "\n",
    "    # The following loop reads the images from the training path, resizes them, and adds them to the list of images.\n",
    "    # It also adds the corresponding label for each image to the list of labels.\n",
    "    for directory_path in glob.glob(test_path+r'/*'):\n",
    "        label = directory_path.split(\"\\\\\")[-1] # extracts the artist name from the directory path.\n",
    "        # print(label)\n",
    "        for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_COLOR) # Read the image in color (BGR format)\n",
    "            img = cv2.resize(img, (size, size))          # Resize the image to the given size, using weighted average values for interpolation.\n",
    "            test_images.append(img)    # Add the processed image to the list of images\n",
    "            test_labels.append(label)  # Add the label to the list of labels, matching the image in the same index in the images list.\n",
    "            \n",
    "    # Convert the lists to numpy arrays\n",
    "    test_images = np.array(test_images)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T18:20:42.535Z",
     "start_time": "2024-03-11T18:20:42.521038Z"
    }
   },
   "id": "dfee0bf8d00f8533",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ??????????????????????? #\n",
    "x_train, y_train, x_test, y_test = resize_and_split(training_path, testing_path, 128)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T18:26:22.578211Z",
     "start_time": "2024-03-11T18:26:12.996812Z"
    }
   },
   "id": "ca2bb9b0f8131e0",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def label_data(train_labels, test_labels):    \n",
    "    \"\"\"\n",
    "    Converts the labels to numbers for the model to be able to process them, utilizing sklearn LabelEncoder.\n",
    "    :param train_labels: The labels of the images in the training dataset.\n",
    "    :param test_labels: The labels of the images in the testing dataset.\n",
    "    :return: The encoded labels for both the training and testing datasets.\n",
    "    \"\"\"\n",
    "    # Converting the labels to numbers for the model to be able to process them.\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(test_labels)\n",
    "    test_labels_encoded = le.transform(test_labels)\n",
    "    le.fit(train_labels)\n",
    "    train_labels_encoded = le.transform(train_labels)\n",
    "\n",
    "    # Giving our data conventional names for easier use in the model.\n",
    "    return train_labels_encoded, test_labels_encoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T18:26:25.217617Z",
     "start_time": "2024-03-11T18:26:25.197663Z"
    }
   },
   "id": "b996936bbe669dd7",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ??????????????????????? #\n",
    "y_train_encoded, y_test_encoded = label_data(y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T18:26:26.776930Z",
     "start_time": "2024-03-11T18:26:26.756976Z"
    }
   },
   "id": "980533235863f917",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def minmax_normalize(train_images, test_images):    \n",
    "    \"\"\"\n",
    "    Normalizes the data to be between 0 and 1 using the min-max normalization.\n",
    "    :param train_images: The training dataset.\n",
    "    :param test_images: The testing dataset.\n",
    "    :return: Normalized training and testing datasets.\n",
    "    \"\"\"\n",
    "    train_images_normalized = []\n",
    "    for img in train_images:\n",
    "        min_val = np.min(img)\n",
    "        max_val = np.max(img)\n",
    "        normalized_img = (img.astype(np.float32) - min_val) / (max_val - min_val)\n",
    "        train_images_normalized.append(normalized_img)\n",
    "\n",
    "    test_images_normalized = []\n",
    "    for img in test_images:\n",
    "        img = img.astype(np.float32)\n",
    "        min_val = np.min(img)\n",
    "        max_val = np.max(img)\n",
    "        normalized_img = (img.astype(np.float32) - min_val) / (max_val - min_val)\n",
    "        test_images_normalized.append(normalized_img)\n",
    "        \n",
    "    return np.array(train_images_normalized), np.array(test_images_normalized)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T18:26:29.614212Z",
     "start_time": "2024-03-11T18:26:29.599229Z"
    }
   },
   "id": "29eacea344be918a",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ??????????????????????? #\n",
    "x_train, x_test = minmax_normalize(x_train, x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T18:26:31.327995Z",
     "start_time": "2024-03-11T18:26:30.550083Z"
    }
   },
   "id": "7b68ab55ebf3b04a",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# The following function is used to vectorize the images by extracting features from them, and aligning them in a dataframe.\n",
    "# The input must be a 4 dimensional array. In our case, an array of colored images. Won't work with grayscale images.\n",
    "def feature_extraction(dataset):\n",
    "    \n",
    "    image_dataset = pd.DataFrame()\n",
    "    \n",
    "    for image in range(dataset.shape[0]): # meaning we iterate through each image\n",
    "    \n",
    "        df = pd.DataFrame()               # We use a temporary dataframe to capture information for each image\n",
    "        \n",
    "        input_img = dataset[image, :,:,:]   # We take the image\n",
    "        img = input_img\n",
    "        \n",
    "        # >> Feature no. 1 - Pixel Values <<\n",
    "        pixel_values = img.reshape(-1)     # Reshaping the image into one vector.\n",
    "        df['Pixel_Value'] = pixel_values   # Adding the pixel values to the dataframe.\n",
    "        \n",
    "        # >> Feature no. 2 - Gabor Filter Responses <<\n",
    "        # This feature captures the texture and directionality of the image,\n",
    "        # which is very important in our case as different artists tend to have unique textures and brush strokes.\n",
    "        \n",
    "        # The following parameters are used to create the Gabor filters.\n",
    "        f  = [0.1, 0.5, 1.0, 1.5, 2.0] # Represents the frequency of the sine component\n",
    "        o  = [0, 30, 60, 90, 120, 150] # Represents the orientation of the filter\n",
    "        sa = [0.5, 0.75, 1.0]          # Represents the spatial aspect ratio of the filter.\n",
    "        sd = [1.0, 2.0, 3.0]           # Represents the standard deviation of the filter\n",
    "        p  = [0, 1*np.pi/2]            # Represents the phase offset of the filter\n",
    "        ks = [2, 4, 6]                 # Represents the kernel size of the filter (K x K)\n",
    "        \n",
    "        # Create all possible combinations of the parameters above.\n",
    "        combos = list(itertools.product(f, o, sa, sd, p, ks)) # All possible combinations of the filter parameters\n",
    "        count = 1\n",
    "        filters = []\n",
    "        filtered_images = []\n",
    "        \n",
    "        # This loop applies all the possible combinations of the Gabor filters with the parameters set above to the image and adds the responses to the dataframe.\n",
    "        for freq, orient, aspect, std_dev, phase_offset, kernel_size in combos:\n",
    "            \n",
    "            gabor_label = 'Gabor' + str(count)  # Create a label for each filter response\n",
    "            \n",
    "            ## Create a gabor filter based on the current combination of parameters and append it to the list of filters.\n",
    "            gabor_filter = cv2.getGaborKernel((kernel_size, kernel_size), std_dev, orient, freq, aspect, phase_offset, ktype=cv2.CV_32F)\n",
    "            filters.append(gabor_filter)\n",
    "\n",
    "            gabor_response = cv2.filter2D(img, cv2.CV_32F, gabor_filter) # Apply the filter to the image\n",
    "            filtered_img = gabor_response.reshape(-1)\n",
    "            df[gabor_label] = filtered_img\n",
    "            \n",
    "            count += 1 # Increment the count for the next filter label\n",
    "\n",
    "        # >> Feature no. 3 - Sobel Edge <<\n",
    "        # This feature captures the edges in the image, which is also important in our case as different artists tend to have unique edges,\n",
    "        # and the edges are also an important aspect in the painting itself.\n",
    "        \n",
    "        edge_sobel = sobel(img)              # Apply the Sobel filter to the image\n",
    "        edge_sobel = edge_sobel.reshape(-1)  # Reshape the response into a vector\n",
    "        df['Sobel'] = edge_sobel             # Add the response to the dataframe\n",
    "    \n",
    "        # Append the dataframe of the current image to the dataset dataframe.\n",
    "        image_dataset = image_dataset.append(df)\n",
    "        \n",
    "    # Return the dataframe of the dataset.\n",
    "    return image_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T18:59:27.154835Z",
     "start_time": "2024-03-11T18:59:27.141847Z"
    }
   },
   "id": "47664d6bd51d568",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "80b02368256c954b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[48], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# ??????????????????????? #\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m img_features \u001B[38;5;241m=\u001B[39m \u001B[43mfeature_extraction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[46], line 47\u001B[0m, in \u001B[0;36mfeature_extraction\u001B[1;34m(dataset)\u001B[0m\n\u001B[0;32m     45\u001B[0m     gabor_response \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mfilter2D(img, cv2\u001B[38;5;241m.\u001B[39mCV_32F, gabor_filter) \u001B[38;5;66;03m# Apply the filter to the image\u001B[39;00m\n\u001B[0;32m     46\u001B[0m     filtered_img \u001B[38;5;241m=\u001B[39m gabor_response\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 47\u001B[0m     df[gabor_label] \u001B[38;5;241m=\u001B[39m \u001B[43mfiltered_img\u001B[49m\n\u001B[0;32m     49\u001B[0m     count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;66;03m# Increment the count for the next filter label\u001B[39;00m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;66;03m# >> Feature no. 3 - Sobel Edge <<\u001B[39;00m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;66;03m# This feature captures the edges in the image, which is also important in our case as different artists tend to have unique edges,\u001B[39;00m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;66;03m# and the edges are also an important aspect in the painting itself.\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[46], line 47\u001B[0m, in \u001B[0;36mfeature_extraction\u001B[1;34m(dataset)\u001B[0m\n\u001B[0;32m     45\u001B[0m     gabor_response \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mfilter2D(img, cv2\u001B[38;5;241m.\u001B[39mCV_32F, gabor_filter) \u001B[38;5;66;03m# Apply the filter to the image\u001B[39;00m\n\u001B[0;32m     46\u001B[0m     filtered_img \u001B[38;5;241m=\u001B[39m gabor_response\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 47\u001B[0m     df[gabor_label] \u001B[38;5;241m=\u001B[39m \u001B[43mfiltered_img\u001B[49m\n\u001B[0;32m     49\u001B[0m     count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;66;03m# Increment the count for the next filter label\u001B[39;00m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;66;03m# >> Feature no. 3 - Sobel Edge <<\u001B[39;00m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;66;03m# This feature captures the edges in the image, which is also important in our case as different artists tend to have unique edges,\u001B[39;00m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;66;03m# and the edges are also an important aspect in the painting itself.\u001B[39;00m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1103\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1061\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Program Files\\JetBrains\\DataSpell 2023.3.4\\plugins\\python-ce\\helpers-pro\\jupyter_debug\\pydev_jupyter_plugin.py:169\u001B[0m, in \u001B[0;36mstop\u001B[1;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[0;32m    167\u001B[0m     frame \u001B[38;5;241m=\u001B[39m suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m frame:\n\u001B[1;32m--> 169\u001B[0m         \u001B[43mmain_debugger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    170\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Program Files\\JetBrains\\DataSpell 2023.3.4\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1184\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1181\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1183\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1184\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Program Files\\JetBrains\\DataSpell 2023.3.4\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1199\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1196\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1198\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1199\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1201\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1203\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# ??????????????????????? #\n",
    "## img_features = feature_extraction(x_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:03:06.764209Z",
     "start_time": "2024-03-11T19:00:13.614287Z"
    }
   },
   "id": "dba6276775ff15c3",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T18:21:02.822888Z",
     "start_time": "2024-03-11T18:21:02.822888Z"
    }
   },
   "id": "6d4be4cd973b3502"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
